# ğŸ¤– Plataforma de Teste de Modelos de IngestÃ£o de PDF

Uma ferramenta de benchmark para avaliar e comparar o desempenho, custo e precisÃ£o de diferentes modelos de InteligÃªncia Artificial na tarefa de extraÃ§Ã£o de dados e resposta a perguntas (Q&A) a partir de documentos PDF, incluindo aqueles com texto digital, imagens ou ambos.

## ğŸ¯ Conceito Central: Quantificando o *Trade-Off*

O objetivo deste projeto nÃ£o Ã© encontrar um Ãºnico "melhor" modelo, mas sim criar uma plataforma que permita **quantificar os trade-offs** entre diferentes abordagens de ingestÃ£o de documentos. A ferramenta foi projetada para responder a perguntas crÃ­ticas de negÃ³cio e engenharia com dados concretos:

* **Custo vs. BenefÃ­cio:** Um modelo pago Ã© 30% mais preciso, mas 500% mais caro. O ganho justifica o custo para este caso de uso?
* **LatÃªncia vs. UX:** Uma resposta local e instantÃ¢nea, mesmo que menos precisa, Ã© melhor para a experiÃªncia do usuÃ¡rio do que uma resposta mais lenta via API?
* **Privacidade vs. Poder:** Os documentos contÃªm dados sensÃ­veis? Se sim, um modelo local que nÃ£o expÃµe dados a terceiros Ã© a Ãºnica opÃ§Ã£o viÃ¡vel?

Esta plataforma transforma "achismo" em uma anÃ¡lise de custo-benefÃ­cio baseada em evidÃªncias.

## âœ¨ Features

* **Interface Web Interativa:** Criada com Streamlit para uma experiÃªncia de usuÃ¡rio amigÃ¡vel, permitindo upload de arquivos e configuraÃ§Ã£o de testes sem tocar no cÃ³digo.
* **Backend Robusto:** Uma API construÃ­da com FastAPI gerencia a lÃ³gica de orquestraÃ§Ã£o dos testes de forma escalÃ¡vel.
* **Arquitetura PlugÃ¡vel:** Adicionar novos modelos de IA Ã© simples, bastando implementar uma classe abstrata e registrÃ¡-la no servidor.
* **AvaliaÃ§Ã£o Inteligente com "IA como Juiz":** Utiliza um LLM (ex: `gpt-4o`) para avaliar semanticamente as respostas dos modelos testados, superando a limitaÃ§Ã£o de uma simples comparaÃ§Ã£o de texto exato.
* **Dashboard de Resultados:** Apresenta uma comparaÃ§Ã£o lado a lado em um scorecard de resumo e uma tabela detalhada com mÃ©tricas de:
    * **PrecisÃ£o** (avaliada pelo "juiz")
    * **LatÃªncia** (em milissegundos)
    * **Custo Estimado** (em USD)

## ğŸ›ï¸ Arquitetura

O sistema opera em uma arquitetura cliente-servidor:

1.  **Frontend (Cliente):** Um dashboard desenvolvido em **Streamlit** (`dashboard.py`) que serve como interface grÃ¡fica para o usuÃ¡rio.
2.  **Backend (Servidor):** Uma API RESTful desenvolvida em **FastAPI** (`main.py`) que recebe as requisiÃ§Ãµes, orquestra a execuÃ§Ã£o dos diferentes modelos de IA e retorna os resultados consolidados.

![Arquitetura do Sistema](https://i.imgur.com/gK9x8C0.png)

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ dashboard.py             # AplicaÃ§Ã£o frontend com Streamlit
â”œâ”€â”€ main.py                  # Servidor backend com FastAPI
â”œâ”€â”€ orchestrator.py          # LÃ³gica que gerencia a execuÃ§Ã£o dos testes e o "IA como Juiz"
â”œâ”€â”€ schemas.py               # Modelos Pydantic para a API
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ base_model.py        # Interface abstrata para todos os modelos
â”‚   â”œâ”€â”€ local_ocr_model.py   # Modelo local com PyMuPDF + Tesseract
â”‚   â””â”€â”€ openai_vision_model.py # Modelo multimodal da OpenAI
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ (coloque seus PDFs de teste aqui)
â”œâ”€â”€ .env.example             # Template para variÃ¡veis de ambiente
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â””â”€â”€ README.md
```

## ğŸ› ï¸ Setup e InstalaÃ§Ã£o

Siga os passos abaixo para configurar e rodar o projeto localmente.

### 1. PrÃ©-requisitos de Sistema

AlÃ©m do Python 3.9+, vocÃª precisarÃ¡ de duas ferramentas de sistema para processamento de PDFs e OCR:

* **Poppler:** NecessÃ¡rio para a biblioteca `pdf2image`.
* **Tesseract OCR:** O motor de OCR para o modelo local.

**No macOS (usando Homebrew):**
```bash
brew install poppler tesseract tesseract-lang
```

**No Linux (Debian/Ubuntu):**
```bash
sudo apt-get update
sudo apt-get install poppler-utils tesseract-ocr tesseract-ocr-por
```

**No Windows:**
* Instale o [Poppler para Windows](https://github.com/oschwartz10612/poppler-windows/releases/) e adicione a pasta `bin` ao seu PATH.
* Instale o [Tesseract OCR](https://github.com/UB-Mannheim/tesseract/wiki) e adicione seu diretÃ³rio de instalaÃ§Ã£o ao PATH.

### 2. ConfiguraÃ§Ã£o do Projeto Python

```bash
# 1. Clone o repositÃ³rio
git clone <url-do-seu-repositorio>
cd <nome-da-pasta>

# 2. Crie e ative um ambiente virtual
python3 -m venv .venv
source .venv/bin/activate

# 3. Instale as dependÃªncias Python
pip install -r requirements.txt

# 4. Configure as variÃ¡veis de ambiente
# Copie o arquivo de exemplo
cp .env.example .env

# Edite o arquivo .env e adicione sua chave da OpenAI
# OPENAI_API_KEY="sk-..."
```

## ğŸš€ Como Rodar

VocÃª precisarÃ¡ de **dois terminais**, ambos com o ambiente virtual ativado.

**No Terminal 1 - Inicie o Servidor Backend:**
```bash
uvicorn main:app --reload
```
Aguarde a mensagem indicando que o servidor estÃ¡ rodando em `http://127.0.0.1:8000`.

**No Terminal 2 - Inicie o Dashboard Frontend:**
```bash
streamlit run dashboard.py
```
Seu navegador abrirÃ¡ automaticamente com a interface da aplicaÃ§Ã£o.

## ğŸ“‹ Como Usar

1.  Acesse o dashboard no seu navegador.
2.  Na coluna da esquerda, **faÃ§a o upload** de um arquivo PDF.
3.  **Selecione os modelos** que deseja comparar.
4.  Na tabela "Defina as Perguntas e Respostas Esperadas", **adicione as perguntas** e as respostas de referÃªncia (gabarito) para o seu documento.
5.  Clique no botÃ£o **"Executar Teste"**.
6.  Aguarde o processamento e analise os resultados na coluna da direita.

## ğŸ§© Como Estender (Adicionar Novos Modelos)

A arquitetura foi projetada para ser extensÃ­vel. Para adicionar um novo modelo:

1.  Crie um novo arquivo em `models/`, por exemplo `models/meu_novo_modelo.py`.
2.  Dentro dele, crie uma classe que herda de `IngestionModel` (definida em `models/base_model.py`) e implemente o mÃ©todo `ingest_and_query`.
3.  Abra o `main.py`, importe sua nova classe e adicione uma instÃ¢ncia dela ao dicionÃ¡rio `AVAILABLE_MODELS`.

O servidor irÃ¡ recarregar e seu novo modelo aparecerÃ¡ automaticamente como uma opÃ§Ã£o no dashboard Streamlit.

## ğŸ“„ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT. Veja `LICENSE` para mais informaÃ§Ãµes.